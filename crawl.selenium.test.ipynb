{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import time\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import TimeoutException, NoSuchElementException\n",
    "import _extractWebPage as ewp\n",
    "\n",
    "\n",
    "def get_page_selenium(driver, url, isGetSubLink=True, delay=14):\n",
    "    # 設置瀏覽器驅動\n",
    "    driver.get(url)\n",
    "    # 等待具有特定class属性的div标签出现并点击\n",
    "    wait = WebDriverWait(driver, delay)\n",
    "    all_data = []  # 存儲所有頁面的數據\n",
    "    page_number = 1\n",
    "\n",
    "    # 設置視窗大小，避免響應式設計影響元素位置\n",
    "    # driver.set_window_size(1920, 1080)\n",
    "\n",
    "    while True:\n",
    "        try:\n",
    "            print(f\"正在處理第 {page_number} 頁\")\n",
    "            time.sleep(2)\n",
    "            \n",
    "            # 獲取當前頁面內容\n",
    "            page_source = driver.page_source\n",
    "            \n",
    "            try:\n",
    "                # 處理頁面內容\n",
    "                pg = ewp.extractor(page_source, unwanted_tags=unwanted_tags, unwanted_elements=unwanted_elements, unwanted_texts= unwanted_text)\n",
    "                \n",
    "\n",
    "                if isGetSubLink == True:\n",
    "                    # print(soup2)\n",
    "                    base_url = 'https://www.esunbank.com/'\n",
    "                    except_url = [] #visited_urls\n",
    "                    all_links = ewp.find_all_links(pg.soup2, base_url, except_url)  # 這邊原來是 soup 全部的內容\n",
    "\n",
    "                    # 將數據添加到列表中\n",
    "                    page_data = {\n",
    "                        'page_number': page_number,\n",
    "                        'url': url,\n",
    "                        'title': pg.title,\n",
    "                        'markdown': pg.markdown_text,\n",
    "                        'all_links': all_links,\n",
    "                    }\n",
    "                    all_data.append(page_data)\n",
    "                    \n",
    "                    # print(i_req, depth, url)\n",
    "                    if len(all_links) > 0:\n",
    "                        print('all-links', all_links)\n",
    "\n",
    "                    # 過濾掉已經在 visited_urls 集合中的 URL\n",
    "                    # all_links = [link for link in all_links if link not in visited_urls]\n",
    "                    # for link in all_links:\n",
    "                    #     i_req += 1\n",
    "                    #     result = get_page_selenium(i_req, url, link, depth, max_depth, result, visited_urls)\n",
    "                    \n",
    "                     # # 這裡可以添加數據保存的邏輯\n",
    "                    # 例如保存到文件：\n",
    "                    with open(log_url, 'w', encoding='utf-8') as f:\n",
    "                        json.dump(all_data, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "                print(f\"成功提取第 {page_number} 頁數據\")\n",
    "            except Exception as e:\n",
    "                print(f\"處理第 {page_number} 頁內容時發生錯誤: {str(e)}\")\n",
    "            \n",
    "\n",
    "\n",
    "            # 尋找並點擊下一頁按鈕\n",
    "            try:\n",
    "                next_button = wait.until(\n",
    "                    EC.element_to_be_clickable((By.CSS_SELECTOR, \"li.page-item.next\"))\n",
    "                    # EC.element_to_be_clickable((By.CSS_SELECTOR, \"li a.group\"))\n",
    "                )\n",
    "                \n",
    "                # 檢查按鈕是否真的可見和可點擊\n",
    "                if not next_button.is_displayed():\n",
    "                    print(\"下一頁按鈕不可見，結束翻頁\")\n",
    "                    break\n",
    "\n",
    "                # 確保按鈕在可視範圍內\n",
    "                driver.execute_script(\"window.scrollTo(0, 0);\") \n",
    "                time.sleep(1)\n",
    "                #把next_button放在畫面的中間\n",
    "                driver.execute_script(\"arguments[0].scrollIntoView({block: 'center'});\", next_button)\n",
    "                time.sleep(1)\n",
    "            \n",
    "                # 使用 JavaScript 點擊\n",
    "                driver.execute_script(\"arguments[0].click();\", next_button)\n",
    "                page_number += 1\n",
    "                \n",
    "                # 可以添加一個最大頁數限制\n",
    "                if page_number > 7:  # 設置合適的最大頁數\n",
    "                    print(\"達到最大頁數限制\")\n",
    "                    break\n",
    "                    \n",
    "            except TimeoutException:\n",
    "                print(\"找不到下一頁按鈕，可能已經是最後一頁\")\n",
    "                break\n",
    "            except Exception as e:\n",
    "                print(f\"點擊下一頁時發生錯誤: {str(e)}\")\n",
    "                break\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"處理頁面時發生未預期的錯誤: {str(e)}\")\n",
    "            break\n",
    "    \n",
    "    print(f\"總共處理了 {page_number} 頁\")\n",
    "    return all_data\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "unwanted_tags = ['script', 'link', 'style', 'meta', 'noscript', 'iframe', 'head', 'header', 'footer', 'select', 'label', 'legend', 'form', 'img', 'input', 'button', 'table', 'figcaption']\n",
    "unwanted_elements = {\n",
    "    'div': ['hide-component', 'l-breadCrumb', 'bread', 'cookie-concent', 'gotop', 'menuBtn', 'darkLoad', 'market-widget', 'scroll-box', 'hotnews', 'important-info', 'nav-main__sub-menu', 'content__header', 'livenews__switch', 'article-function', 'fbmsg-box', 'box__promo', 'relatednews', 'ad-recommend', 'ad-box', 'theme-switch', 'l-bottomInfo__customerservice','l-warning'],\n",
    "    'section': ['l-rating','l-cardService','l-bottomInfo'],\n",
    "    'nav': ['paginationNav'],\n",
    "    'p': ['hint', 'box-title'],\n",
    "    'a': ['goMain', 'header__main-logo-square', 'nav-main__collapse-btn'],\n",
    "    'ul': ['bread-crumb'],\n",
    "    'li': ['nav-main__menu-item']\n",
    "}\n",
    "wanted_elements = {\n",
    "    'ul': ['paginationList'],\n",
    "}\n",
    "unwanted_text = {\n",
    "    'span': ['讀取中'],\n",
    "    'a': [':::','進階篩選'],\n",
    "    'h1': ['# 優惠總覽'],\n",
    "    'p': ['消費生活首選，就愛刷玉山卡！']\n",
    "}\n",
    "# start_url = \"https://www.esunbank.com/zh-tw/personal/credit-card/discount/shops/all\"\n",
    "# start_url = \"https://www.esunbank.com/zh-tw/about/faq\"\n",
    "start_url = \"https://www.esunbank.com/zh-tw/about/faq/faqlist?tag=credit-card\"\n",
    "log_url = \"Result/玉山銀行faq_CreditCard/output.json\"\n",
    "\n",
    "def main():\n",
    "    try:\n",
    "        driver = webdriver.Chrome(options=ewp.init_chrome_option())\n",
    "        all_pages_data = get_page_selenium(driver, start_url)\n",
    "        # 處理收集到的數據\n",
    "        print(f\"總共收集到 {len(all_pages_data)} 頁的數據\")\n",
    "        \n",
    "        # # 這裡可以添加數據保存的邏輯\n",
    "        # # 例如保存到文件：\n",
    "        # with open(log_url, 'w', encoding='utf-8') as f:\n",
    "        #     json.dump(all_pages_data, f, ensure_ascii=False, indent=2)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"主程序執行錯誤: {str(e)}\")\n",
    "    finally:\n",
    "        # 如果需要關閉瀏覽器，取消下面的註釋\n",
    "        # driver.quit()\n",
    "        pass\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# 讀取 JSON 資料\n",
    "work_folder = \"玉山銀行faq\"\n",
    "log_url = f\"Result/{work_folder}/output.json\"\n",
    "out_url = f\"Result/{work_folder}/output.all_links.json\" \n",
    "with open(log_url, 'r', encoding='utf-8') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "# 提取 URL\n",
    "urls = [item['all_links'] for item in data]\n",
    "\n",
    "# 將 URL 轉換為集合，以去除重複項\n",
    "unique_urls = set()\n",
    "for sublist in urls:\n",
    "    unique_urls.update(sublist)\n",
    "\n",
    "# 對 URL 進行排序\n",
    "sorted_urls = sorted(unique_urls)\n",
    "\n",
    "# 將 URL 寫入文字檔\n",
    "with open(out_url, 'w', encoding='utf-8') as f:\n",
    "    for url in sorted_urls:\n",
    "        f.write(url + '\\n')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "f-string: single '}' is not allowed (3246175747.py, line 56)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[2], line 56\u001b[1;36m\u001b[0m\n\u001b[1;33m    out_url = f\"Result/{work_folder}}/MD/{format_page_number}.{pg.title}.md\"\u001b[0m\n\u001b[1;37m                                    ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m f-string: single '}' is not allowed\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import TimeoutException, NoSuchElementException\n",
    "import _extractWebPage as ewp\n",
    "\n",
    "work_folder = \"玉山銀行faq\"\n",
    "all_links_url = f\"Result/{work_folder}/output.all_links.json\" \n",
    "\n",
    "with open(all_links_url, 'r', encoding='utf-8') as f:\n",
    "    urls = f.read().split('\\n')\n",
    "\n",
    "page_number = 0\n",
    "driver = webdriver.Chrome(options=ewp.init_chrome_option())\n",
    "\n",
    "unwanted_tags = ['script', 'link', 'style', 'meta', 'noscript', 'iframe', 'head', 'header', 'footer', 'select', 'label', 'legend', 'form', 'img', 'input', 'button', 'table', 'figcaption']\n",
    "unwanted_elements = {\n",
    "    'div': ['hide-component', 'l-breadCrumb', 'bread', 'cookie-concent', 'gotop', 'menuBtn', 'darkLoad', 'market-widget', 'scroll-box', 'hotnews', 'important-info', 'nav-main__sub-menu', 'content__header', 'livenews__switch', 'article-function', 'fbmsg-box', 'box__promo', 'relatednews', 'ad-recommend', 'ad-box', 'theme-switch', 'l-bottomInfo__customerservice','l-warning'],\n",
    "    'section': ['l-rating','l-cardService','l-bottomInfo'],\n",
    "    'nav': ['paginationNav'],\n",
    "    'p': ['hint', 'box-title'],\n",
    "    'a': ['goMain', 'header__main-logo-square', 'nav-main__collapse-btn'],\n",
    "    'ul': ['bread-crumb'],\n",
    "    'li': ['nav-main__menu-item']\n",
    "}\n",
    "unwanted_text = {\n",
    "    'span': ['讀取中'],\n",
    "    'a': [':::','進階篩選'],\n",
    "    'h1': ['# 優惠總覽'],\n",
    "    'p': ['消費生活首選，就愛刷玉山卡！']\n",
    "}\n",
    "\n",
    "for url in urls:\n",
    "    driver.get(url)\n",
    "    # wait = WebDriverWait(driver, 3)\n",
    "    page_number += 1\n",
    "    page_source = driver.page_source\n",
    "    try:\n",
    "        pg = ewp.extractor(page_source, unwanted_tags=unwanted_tags, unwanted_elements=unwanted_elements, unwanted_texts= unwanted_text)\n",
    "        base_url = 'https://www.esunbank.com/'\n",
    "        except_url = [] #visited_urls\n",
    "        # all_links = ewp.find_all_links(pg.soup2, base_url, except_url)  # 這邊原來是 soup 全部的內容\n",
    "        format_page_number = f\"{page_number:04d}\"\n",
    "        \n",
    "        # # 將數據添加到列表中\n",
    "        # page_data = {\n",
    "        #     'page_number': format_page_number,\n",
    "        #     'url': url,\n",
    "        #     'title': pg.title,\n",
    "        #     'text': pg.extract_text,\n",
    "        #     'markdown': pg.markdown_text,\n",
    "        # }\n",
    "        # print(f\"抓取{format_page_number} {url} 中...\")\n",
    "\n",
    "        out_url = f\"Result/{work_folder}/MD/{format_page_number}.{pg.title}.md\"\n",
    "        with open(out_url, 'w', encoding='utf-8') as f:\n",
    "            f.write(f\"參考網址：{url}\\n\\n\")\n",
    "            f.write(pg.markdown_text)\n",
    "        \n",
    "        out_url2 = f\"Result/{work_folder}/TXT/{format_page_number}.{pg.title}.txt\"\n",
    "        with open(out_url2, 'w', encoding='utf-8') as f:\n",
    "            f.write(f\"參考網址：{url}\\n\\n\")\n",
    "            f.write(pg.extract_text)\n",
    "            \n",
    "\n",
    "        print(f\"成功提取第 {page_number} 頁數據\")\n",
    "    except Exception as e:\n",
    "        print(f\"處理第 {page_number} {url} 頁內容時發生錯誤: {str(e)}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
