{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To build a Retrieval Augmented Generation (RAG) pipeline with Haystack, you need three main components:\n",
      "\n",
      "1. Retriever\n",
      "2. PromptBuilder\n",
      "3. Generator\n",
      "\n",
      "By combining these components, you can design and scale your interactions with large language models (LLMs) effectively. This pipeline enables you to retrieve relevant information and generate responses based on user queries.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from haystack import Pipeline, PredefinedPipeline\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = open(\"../apikey/chatGPT_apikey.txt\", \"r\").read()\n",
    "\n",
    "pipeline = Pipeline.from_template(PredefinedPipeline.CHAT_WITH_WEBSITE)\n",
    "result = pipeline.run({\n",
    "    \"fetcher\": {\"urls\": [\"https://netmag.tw/2024/06/04/computex-2024-nvidia-unveils-ai-gpus-and-connectivity\"]},\n",
    "    \"prompt\": {\"query\": \"微軟有推出什麼最新的技術??\"}}\n",
    ")\n",
    "print(result[\"llm\"][\"replies\"][0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
